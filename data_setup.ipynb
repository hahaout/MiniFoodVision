{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Now we have chose FoodVision from PyTorvh torchvision to work with\n",
    "\n",
    "We need to:\n",
    "1. Prepare our data from torch vision\n",
    "2. Build a model( we will use pre-build model to make comparison)\n",
    "    * 1. Choose an optimizer and loss function\n",
    "    * 2. Design a training and testing loop\n",
    "3. Fit the model to the data and make a prediction\n",
    "4. Evaluate the model\n",
    "5. Improve through experiment\n",
    "6. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model to the data and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/food_10_percent/train'),\n",
       " WindowsPath('data/food_10_percent/test'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setupo image path for train and testing\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "image_path = Path(\"data/\")\n",
    "image_data = image_path / \"food_10_percent\"\n",
    "\n",
    "train_dir = image_data /  \"train\"\n",
    "test_dir = image_data / \"test\"\n",
    "\n",
    "train_dir,test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step for fiiting data into model\n",
    "* image path -> image -> image tensor ->  dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Compose(\n",
       "     Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "     ToTensor()\n",
       " ),\n",
       " Compose(\n",
       "     Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "     TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
       "     ToTensor()\n",
       " ))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Create transformer for the image\n",
    "simple_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "simple_transforms, train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1b736942dd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1b7369c5010>,\n",
       " 101)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataloader for training and testing loop\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKER = os.cpu_count()\n",
    "\n",
    "# Convert image into datasets\n",
    "train_datasets_20 = datasets.ImageFolder(root=train_dir,\n",
    "                                           transform=train_transforms)\n",
    "test_datasets_20 = datasets.ImageFolder(root=test_dir,\n",
    "                                          transform=simple_transforms)\n",
    "\n",
    "# get class name from here\n",
    "classes = train_datasets_20.classes\n",
    "\n",
    "# Convert datasets into dataloader\n",
    "train_dataloader_20 = DataLoader(dataset=train_datasets_20,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=NUM_WORKER,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "test_dataloader_20 = DataLoader(dataset=test_datasets_20,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=NUM_WORKER,\n",
    "                                 pin_memory=True)\n",
    "train_dataloader_20, test_dataloader_20, len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code is done let's put all of them into a function and translate into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader for training and testing loop\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "def create_dataloaders(train_dir:str,\n",
    "               test_dir:str,\n",
    "               train_transforms: torchvision.transforms.Compose,\n",
    "               test_transforms: torchvision.transforms.Compose,\n",
    "               batch_size: int,\n",
    "               num_worker: int =os.cpu_count()):\n",
    "    \n",
    "    # convert image from path into datsets\n",
    "    train_datasets = datasets.ImageFolder(root=train_dir,\n",
    "                                          transform=train_transforms,\n",
    "                                          )\n",
    "    test_datasets = datasets.ImageFolder(root=test_dir,\n",
    "                                         transform= test_transforms)\n",
    "    \n",
    "    # Get classes\n",
    "    classes = train_datasets.classes\n",
    "    \n",
    "    # convert datsets into dataloader\n",
    "    train_dataloader = DataLoader(train_datasets,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=num_worker,\n",
    "                                  pin_memory=True)\n",
    "    \n",
    "    test_dataloader = DataLoader(test_datasets,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=num_worker,\n",
    "                                 pin_memory=True)\n",
    "    \n",
    "    return train_dataloader, test_dataloader, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now data has been set\n",
    "\n",
    "Let's train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a900b0e1584c2c8a0ccf2326a7f8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 4.6206 | train_acc: 0.0095 | test_loss: 4.6181 | test_acc: 0.0091\n",
      "Epoch: 2 | train_loss: 4.6174 | train_acc: 0.0098 | test_loss: 4.6176 | test_acc: 0.0119\n",
      "Epoch: 3 | train_loss: 4.6174 | train_acc: 0.0103 | test_loss: 4.6182 | test_acc: 0.0087\n",
      "Epoch: 4 | train_loss: 4.6170 | train_acc: 0.0104 | test_loss: 4.6175 | test_acc: 0.0087\n",
      "Epoch: 5 | train_loss: 4.6172 | train_acc: 0.0103 | test_loss: 4.6179 | test_acc: 0.0087\n"
     ]
    }
   ],
   "source": [
    "from scripts import data_setup, engine, model\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "BATCH_SIZE = 32\n",
    "#\n",
    "device = \"cuda\" if T.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dataloader_20, test_dataloader_20, classes = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                                 test_dir=test_dir,\n",
    "                                                                                 train_transforms=train_transforms,\n",
    "                                                                                 test_transforms=simple_transforms,\n",
    "                                                                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "#train_dataloader_20, test_dataloader_20, len(classes)\n",
    "\n",
    "# create model\n",
    "modelV1 = model.VGGV0(input_size=3,\n",
    "                    hidden_units=32,\n",
    "                    output_size=len(classes)).to(device)\n",
    "\n",
    "#modelV1\n",
    "# setup optimizer and loss fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = T.optim.Adam(params=modelV1.parameters(),\n",
    "                         lr=0.01)\n",
    "\n",
    "# start training\n",
    "\n",
    "results =engine.train(model=modelV1,\n",
    "                    train_dataloader = train_dataloader_20,\n",
    "                    test_dataloader = test_dataloader_20,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=5,\n",
    "                    device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.617881008341342, 0.00870253164556962)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = engine.test_step(\n",
    "    modelV1,test_dataloader_20,loss_fn,device\n",
    ")\n",
    "test_loss,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
